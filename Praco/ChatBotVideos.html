<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chat bots and videos</title>
 <style>
   img{
    float:left;
    padding:5px;
    max-width: 100%; 
    height: auto;    
    display: block;
    }
    article{
        font-size:20px;
        background-color: lightgrey;
       
    }
    h2{
        color: rgb(32, 164, 32);
        text-shadow: 2px 2px 5px red;
    
    }
    </style>
</head>
<body style="background-color:lightgrey;">
            <article style="border-style:inset;border-color:black;border-radius: 10px;border-width:5px;padding:5px;">
            <h2>Even the most advanced chatbots don’t recognize AI-generated videos</h2>
             <img src="images/AIandVideos.png" alt="A picture of a frustrated AI">
            An experiment by NewsGuard, a media-reliability rating service, found that in most cases, leading AI chatbots couldn’t tell when videos were generated by OpenAI’s text-to-video tool Sora. Even OpenAI’s own ChatGPT is faltering.<br><br>
            OpenAI’s Sora is really popular among AI aficionados – and misinformation actors who like the fact that the tool is able to fool many into thinking that its videos are authentic.<br><br>
            For instance, not that long ago, social media platforms were full of videos allegedly showing Ukrainian soldiers begging for mercy, weeping, and surrendering on the front lines – but they were all Sora-generated deepfakes.<br><br>
            Now, it turns out that Sora can fool AI models themselves. A NewsGuard test demonstrated that three leading chatbots – xAI’s Grok, OpenAI’s ChatGPT, and Google’s Gemini – overwhelmingly fail to detect fake videos unless they’re watermarked.<br><br>
            Grok, ChatGPT, and Gemini didn’t identify non-watermarked Sora videos as AI-generated 95%, 92.5%, and 78% of the time, respectively, when prompted.<br><br>
            ChatGPT’s 92.5% failure rate is particularly notable, since the same company, OpenAI, created and owns both ChatGPT and Sora.<br><br>
            According to NewsGuard, even with watermarked videos, two of the three chatbots sometimes stumbled. Grok failed to identify watermarked content as AI-generated 30% of the time, and ChatGPT missed the mark 7.5% of the time. Only Gemini succeeded in all tests.<br><br>
            Moreover, these Sora watermarks are extremely easy to remove. In fact, soon after Sora launched last February, multiple firms began offering free Sora watermark removal tools. NewsGuard used one of them and easily duped all three chatbots, the organization said.<br><br>
            
        </article>
</body>

</html>
